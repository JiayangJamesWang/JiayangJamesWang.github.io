<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 180 Project 4</title>
    <link href="https://fonts.googleapis.com/css?family=Merriweather:300,700,300italic,700italic|Source+Sans+Pro:900" rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Fira Code' rel='stylesheet'>
    <style>
        body {
            background-color: #fafafa;
            font-family: "Merriweather", Georgia, serif;
            font-weight: 300;
            font-size: 1rem;
            line-height: 2;
            margin: 0;
            padding: 10px;
            display: flex;
            flex-direction: column;
        }
        .header {
            background-color: #ddddff;
            padding: 20px;
            text-align: center;
        }
        .content-wrapper {
            display: flex;
            flex-grow: 1;
        }
        .vertical_slide {
            overflow-x: auto;
        }
        nav {
            width: 225px;
            padding: 5;
            background-color: #fafafa;
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: scroll;
        }
        nav ul {
            list-style-type: disc;
            border-left: 1px;
        }
        nav ul li {
            margin-bottom: 10px;
        }
        nav ul li a {
            text-decoration: none;
            color: #333;
            display: block;
        }
        .nav-section-divider {
            border-top: 1px solid #ccc;
            margin: 10px 0;
        }
        .section-divider {
            border-top: 10px solid #ddddff;
            margin: 50px 0;
        }
        main {
            flex-grow: 1;
            margin: auto;
            padding: 80px;
        }
        .section {
            margin-bottom: 40px;
        }
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            margin: auto;
            width: 80%;
            padding: 10px;
            gap: 20px;
        }
        .grid-item {
            border: 5px solid #ddddff;
            padding: 10px;
            text-align: center;
        }
        .grid-item img {
            max-width: 100%;
            max-height: 500px;
            height: auto;
        }
        code {
            font-family: 'Fira Code';
            background-color: #f5f0ff;
            border-radius: 0.25rem;
            color:#7400f1;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>(Auto)stitching and Photo Mosaics</h1>
        <h2>CS 180 Project 4</h2>
        <p>Jiayang Wang | jiayang.wang@berkeley.edu</p>
    </div>
    <div class="content-wrapper">
        <vertical_slide>
            <nav>
                <ul>
                    <li><a href="#introduction">Introduction</a></li>

                    <div class="nav-section-divider"></div>

                    <li><a href="#part_a">Part A: Image Warping and Mosaicing</a></li>
                    <ul>
                        <li><a href="#pictures">Shoot the Pictures</a></li>
                        <li><a href="#homographies">Recover Homographies</a></li>
                        <li><a href="#warping">Warp the Images</a></li>
                        <li><a href="#rectification">Image Rectification</a></li>
                        <li><a href="#blending">Blend the Images into A Mosaic</a></li>
                    </ul>
                    
                    <div class="nav-section-divider"></div>

                    <li><a href="#part_b">Part B: Feature Matching for Autostitching</a></li>
                    <ul>
                        <li><a href="#detector">Harris Interest Point Detector</a></li>
                        <li><a href="#anms">Adaptive Non-Maximal Suppression</a></li>
                        <li><a href="#extraction">Feature Descriptor Extraction</a></li>
                        <li><a href="#matching">Feature Matching</a></li>
                        <li><a href="#ransac">RANSAC for Robust Homography Estimation</a></li>
                        <li><a href="#results">Results using Autostitching</a></li>
                    </ul>

                    <div class="nav-section-divider"></div>

                    <li><a href="#reflection">Reflection</a></li>
                </ul>
            </nav>
        </vertical_slide>
        <main>
            <div id="introduction" class="main">
                <h1>Introduction</h1>
                <p>The first part of this project goes through the basics of stitching image mosaics, including computing
                    homographies through correspondence points, using the homographies to warp images such that the correspondence points overlap with
                    each other, and blending warped images using Laplacian pyramid.
                </p>
            </div>

            <div class="section-divider"></div>

            <div id="part_a" class="main">
                <h1>Part A: Image Warping and Mosaicing</h1>
            </div>
            <div id="pictures" class="section">
                <h2>Shoot the Pictures</h2>
                <p>To capture sets of photos that are projective transformations of each other, I need to fix the center of projection for each set.
                    Therefore, I hold my phone such that the camera is on the rotation axis, and make sure each image in a set has about 40% to 70%
                    overlap with the center image.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/univhall_1.jpg" alt="univhall_1.jpg">
                        <p>univhall_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/univhall_2.jpg" alt="univhall_2.jpg">
                        <p>univhall_2.jpg<br>Center Image</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/univhall_3.jpg" alt="univhall_3.jpg">
                        <p>univhall_3.jpg</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/entrance_1.jpg" alt="entrance_1.jpg">
                        <p>entrance_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/entrance_2.jpg" alt="entrance_2.jpg">
                        <p>entrance_2.jpg<br>Center Image</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/entrance_3.jpg" alt="entrance_3.jpg">
                        <p>entrance_3.jpg</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/night_1.jpg" alt="night_1.jpg">
                        <p>night_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/night_2.jpg" alt="night_2.jpg">
                        <p>night_2.jpg<br>Center Image</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/night_3.jpg" alt="night_3.jpg">
                        <p>night_3.jpg</p>
                    </div>
                </div>
            </div>

            <div id="homographies" class="section">
                <h2>Recover Homographies</h2>
                <p>For each pair of images, I need to recover a projective transformation below, where <code>H</code> is the homography matrix with 8 degrees of freedom.    
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A2/formula_H.png" alt="formula_H.png">
                    </div>
                    <div class="grid-item">
                        <img src="./A2/formula_projective.png" alt="formula_projective.png">
                    </div>
                </div>
                <p>After manually entering the correspondence points for each pair of images using <code>ginput</code>, I used <code>np.linalg.pinv</code> to
                    calculate the least-square solution for <code>H</code> in the following system, where each <code>(x, y)</code> and <code>(x', y')</code> is a pair of
                    correspondence points in the source and the target image.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A2/formula_least_squares.png" alt="formula_least_squares.png">
                    </div>
                </div>
                <p>
                    Each coordinate <code>(x, y)</code> in the source image can be transformed to the target coordinate <code>(x', y')</code> by multiplying <code>H</code>
                    and then dividing <code>w</code>, which acts as a scaling factor.
                </p>
            </div>

            <div id="warping" class="section">
                <h2>Warp the Images</h2>
                <p>After calculating the homography for each pair of images, I warped the source image to the target image using the following warping algorithm:
                </p>
                <p>1. Get the coordinates of the 4 corners of the source image and apply the homography on them. Use <code>skimage.draw.polygon</code> on the result coordinates
                    to get all pixels in the transformed polygon that will be used in inverse warping, as well as perdicting the size of the warped image.<br>
                    2. For each pixel in this polygon, apply the inverse of the homography on its coordinate to get the sampling coordinate in the source image, and then interpolate
                     this pixel from the source image using <code>scipy.interpolate.griddata</code>.<br>
                    3. For pixels without any values in the warped image, set the values of the alpha channel to 0. This helps with image blending.
                </p>
            </div>

            <div id="rectification" class="section">
                <h2>Image Rectification</h2>
                <p>With the above algorithms, I can use projective transformations to warp images between each other by defining correspondences.
                    For image rectification, I manually marked the four corners of the known rectangular object in the input image, and then defines the correspondences
                    using a function that calculates the corner coordinates of a rectangle with similar size to the input corners.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/computer_instruct.png" alt="computer_instruct.png">
                        <p>computer.png<br>+ Correspondences</p>
                    </div>
                    <div class="grid-item">
                        <img src="./A3/computer.png_rectified.png" alt="computer.png_rectified.png">
                        <p>Rectified</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/roof_instruct.jpg" alt="roof_instruct.jpg">
                        <p>roof.jpg<br>+ Correspondences</p>
                    </div>
                    <div class="grid-item">
                        <img src="./A3/roof.jpg_rectified.png" alt="roof.jpg_rectified.png">
                        <p>Rectified</p>
                    </div>
                </div>
                <p>Using the four pairs of correspondences, I recovered the homography between the input image and the calculated rectangle, and then used the warping algorithm
                    described above to warp the input image such that the known rectangular object is now a rectangle in the output image.
                </p>
            </div>

            <div id="blending" class="section">
                <h2>Blend the Images into A Mosaic</h2>
                <p>To stitch a set of three photos into a mosaic, I defined the base photo as the "center" photo in the set, and marked the correspondence points between
                    the base photo and the other two photos. In this case, I marked 9 points for each images, as this overdetermined system is relatively more stable and
                    less prone to noise compare to only 4 points. Then, I warped other photos into the base photo using the algorithms described above. However, notice that 
                    when combining the warped photos and creating the mosaic, simply overwriting photos with each other will lead to visible edge artifacts. 
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/univhall_2.jpg_mosaic_naive.png" alt="univhall_2.jpg_mosaic_naive.png">
                        <p>Naive Blending with Artifacts</p>
                    </div>
                </div>
                <p>To remove these
                    artifacts, I first calculated a distance transform mask for each warped photo, where each pixel in the mask shows its Euclidean distance to the closest
                    boundary of the warped image.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/image_1_mask.png" alt="image_1_mask.png">
                        <p>univhall_1.jpg<br>Distance Transform</p>
                    </div>
                    <div class="grid-item">
                        <img src="./A4/base_mask.png" alt="base_mask.png">
                        <p>univhall_2.jpg<br>Distance Transform</p>
                    </div>
                    <div class="grid-item">
                        <img src="./A4/image_2_mask.png" alt="image_2_mask.png">
                        <p>univhall_3.jpg<br>Distance Transform</p>
                    </div>
                </div>
                <p>After getting the distance transform masks, I computed a 2-level Laplacian pyramid on each photo to produce a low-pass filtered
                    blurred photo and a high-pass filtered photo with only high frequency details, and then blend the low-pass photos and high-pass photos using different
                    methods.
                </p>
                <p>The overlapping region of each pair of low-pass photos are blended using a weighted linear combination, where the weights are determined by the
                    distance transform masks, such that pixels closer toward the center of each photo have higher weights.
                </p>
                <p>The overlapping region of each pair of high-pass photos are blended using a binary mask calculated from the distance transform masks, such that for each pixel
                    in the overlapping region, its value is taken from the high-pass photo with higher distance transform value.
                </p>
                <p>Using this blending method, the result has smoother transition and much less artifacts
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/univhall_1.jpg" alt="univhall_1.jpg">
                        <p>univhall_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/univhall_instruct.jpg" alt="univhall_instruct.jpg">
                        <p>univhall_2.jpg<br>+ Correspondences</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/univhall_3.jpg" alt="univhall_3.jpg">
                        <p>univhall_3.jpg</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/univhall_2.jpg_mosaic.png" alt="univhall_2.jpg_mosaic.png">
                        <p>univhall Mosiac</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/entrance_1.jpg" alt="entrance_1.jpg">
                        <p>entrance_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/entrance_instruct.jpg" alt="entrance_instruct.jpg">
                        <p>entrance_2.jpg<br>+ Correspondences</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/entrance_3.jpg" alt="entrance_3.jpg">
                        <p>entrance_3.jpg</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/entrance_2.jpg_mosaic.png" alt="entrance_2.jpg_mosaic.png">
                        <p>entrance Mosiac</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/night_1.jpg" alt="night_1.jpg">
                        <p>night_1.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/night_instruct.jpg" alt="night_instruct.jpg">
                        <p>night_2.jpg<br>+ Correspondences</p>
                    </div>
                    <div class="grid-item">
                        <img src="./data/night_3.jpg" alt="night_3.jpg">
                        <p>night_3.jpg</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/night_2.jpg_mosaic.png" alt="night_2.jpg_mosaic.png">
                        <p>night Mosiac</p>
                    </div>
                </div>
            </div>
            
            <div class="section-divider"></div>

            <div id="part_b" class="main">
                <h1>Part B: Feature Matching for Autostitching</h1>
                <p>For part B, I followed <a href="https://inst.eecs.berkeley.edu/~cs180/fa24/hw/proj4/Papers/MOPS.pdf">this paper</a> to implement
                    a system for automatically stitching images into a mosaic.
                </p>
            </div>

            <div id="detector" class="section">
                <h2>Harris Interest Point Detector</h2>
                <p>To automatically find interest points that can be matched into correspondences, I used the Harris interest point detector to locate
                    all "corners": image patches around an interest point whose sum of squared differences with their immediate neighbors, or their
                    corner strengths, are above a certain threshold.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./data/univhall_2.jpg" alt="univhall_2.jpg">
                        <p>univhall_2.jpg</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B1/univhall_2.jpg_corners.png" alt="univhall_2.jpg_corners.png">
                        <p>univhall_2.jpg<br>Harris Corners</p>
                    </div>
                </div>
                <p>As we can see on the above images with all Harris corners overlaid on it, this detector produces extremely dense set of Harris corners
                    without any suppression.
                </p>
            </div>

            <div id="anms" class="section">
                <h2>Adaptive Non-Maximal Suppression</h2>
                <p>Since too much interest points causes redundant computations, I used the Adaptive Non-Maximal Suppression (ANMS) algorithm that
                    reduces the number of interest points while distribute them evenly throughout the image. In ANMS, only interest points that have
                    the local maximum corner strength in a neighbourhood of radius <code>r</code> pixels are retained. The algorithm starts with
                    the maximum <code>r</code>, which will find the interest point with global maximum corner strength, and gradually decrease
                    <code>r</code>, adding more local maximum interest point into the list, until the number of interest points in the
                    list reached the target amount, which in my case is the top-500 points for each image.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B1/univhall_2.jpg_corners.png" alt="univhall_2.jpg_corners.png">
                        <p>univhall_2.jpg<br>Without Suppression</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B1/univhall_2.jpg_anms.png" alt="univhall_2.jpg_anms.png">
                        <p>univhall_2.jpg<br>ANMS with <code>n_ip = 500</code> and <code>c_robust = 0.9</code></p>
                    </div>
                </div>
            </div>

            <div id="extraction" class="section">
                <h2>Feature Descriptor Extraction</h2>
                <p>After ANMS returned the interest points, the next step is to match each interest point with its correspondence
                    across the image. To do this, I extracted feature descriptors by sampling a 40x40 patch around each interest point,
                    and downsample the large patches into 8x8 descriptors using a Gaussian low-pass filter. Since the descriptors
                    are blurred by the low-pass filter, downsampling helps with avoiding aliasing.
                </p>
                <p>Each 8x8 descriptor is also bias/gain-normalized such that for each descriptor, the mean of the pixel intensity is 0 and
                    the standard deviation is 1. This normalization makes descriptors invariant to affine changes in intensity values.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B2/univhall_2.jpg_descriptor_1.jpg" alt="univhall_2.jpg_descriptor_1.jpg">
                        <p>A Descriptor of univhall_2.jpg<br>+ Low-Pass Filter<br>+ Bias/Gain-Normalization</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B2/univhall_2.jpg_descriptor_1_color.png" alt="univhall_2.jpg_descriptor_1_color.png">
                        <p>The Original 40x40 Patch</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B2/night_2.jpg_descriptor_1.jpg" alt="night_2.jpg_descriptor_1.jpg">
                        <p>A Descriptor of night_2.jpg<br>+ Low-Pass Filter<br>+ Bias/Gain-Normalization</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B2/night_2.jpg_descriptor_1_color.png" alt="night_2.jpg_descriptor_1_color.png">
                        <p>The Original 40x40 Patch</p>
                    </div>
                </div>
            </div>
            
            <div id="matching" class="section">
                <h2>Feature Matching</h2>
                <p>To match feature descriptors between two images, I first computed the pairwise L2 distances between all descriptors in
                    one image and all descriptors in the other image. For each descriptor, I then find its nearest neighbor in the distance
                    matrix, which is its potential matching descriptor in the other image.
                </p>
                <p>To increase the certainty for each match, I used
                    Lowe's Trick that thresholds on the ratio between the distance to the nearest neighbor and the second nearest neighbor.
                    The ratio will only be below the threshold if the nearest neighbor is a much better match than the second nearest neighbor,
                    as well as all other further matches, thus is more likely to be the true match.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B3/entrance_2.jpg_entrance_1.jpg_corresponence.png" alt="entrance_2.jpg_entrance_1.jpg_corresponence.png">
                        <p>entrance_1.jpg & entrance_2.jpg<br>Matched Correspondences with <code>threshold = 0.8</code></p>
                    </div>
                </div>
                <p>While most of the matched correspondences looked correct, some visible outliers were present in the result images.</p>
            </div>

            <div id="ransac" class="section">
                <h2>RANSAC for Robust Homography Estimation</h2>
                <p>As seen in the results of the last part, there are still some incorrect matches between correspondences. Since least-square estimations
                    are sensitive to outliers, I used a Random Sample Consensus (RANSAC) algorithm to increase the robustness of homography estimation.
                    For each loop in RANSAC, the algorithm randomly picks 4 pairs of correspondences from the result in the last part, and compute the exact
                    homography using these 8 points. Then, the algorithm applies the homography to all points and count the number of inliers: points whose
                    distance to their matched correspondences after warping is less than 2 pixels. The algorithm keeps track of the largest set of inliers
                    throughtout the loops, and after enough iterations (5000 in this case), uses this largest set of inliers to compute the least-square
                    homography. Using this RANSAC algorithm, I was able to filter out the correspondences that does not follow the majority homography,
                    thus increasing the robustness of the homography estimation against outliers.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B4/entrance_2.jpg_entrance_1.jpg_ransac.png" alt="entrance_2.jpg_entrance_1.jpg_ransac.png">
                        <p>entrance_1.jpg & entrance_2.jpg<br>After RANSAC with 5000 Iterations</p>
                    </div>
                </div>
            </div>

            <div id="results" class="section">
                <h2>Results using Autostitching</h2>
                <p>I applied all steps above on the same images from part A, and the results are shown below, manually and automatically stitched results
                    side by side.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/univhall_2.jpg_mosaic.png" alt="univhall_2.jpg_mosaic.png">
                        <p>univhall Manually Stitched Mosaic</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B4/univhall_2.jpg_automosaic.png" alt="univhall_2.jpg_automosaic.png">
                        <p>univhall Autostitched Mosaic</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/entrance_2.jpg_mosaic.png" alt="entrance_2.jpg_mosaic.png">
                        <p>entrance Manually Stitched Mosaic</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B4/entrance_2.jpg_automosaic.png" alt="entrance_2.jpg_automosaic.png">
                        <p>entrance Autostitched Mosaic</p>
                    </div>
                </div>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./A4/night_2.jpg_mosaic.png" alt="night_2.jpg_mosaic.png">
                        <p>night Manually Stitched Mosaic</p>
                    </div>
                    <div class="grid-item">
                        <img src="./B4/night_2.jpg_automosaic.png" alt="night_2.jpg_automosaic.png">
                        <p>night Autostitched Mosaic</p>
                    </div>
                </div>
                <p>By showing both manually and automatically stitched
                    results next to each other, it is easy to see that autostitching produces clearer results and reduces visual artifacts such as ghosting,
                    since it is not affected by noises and error caused by manual inputs.
                </p>
                <div class="grid">
                    <div class="grid-item">
                        <img src="./B4/univhall_compare.png" alt="univhall_compare.png">
                        <p>Left: Manual, Right: Autostitched</p>
                    </div>
                </div>
            </div>

            <div class="section-divider"></div>

            <div id="reflection" class="section">
                <p>The coolest thing I learned from this project is how the computer "understands" an image completely different from human, yet we can use techniques
                    like Harris corner detection and feature matching to achieve the same, and even better results. The moment that clever techniques like ANMS and RANSAC
                    filtered out all redundent data and keeped only the best correspondences is also very satisfying.
                </p>
            </div>
        </main>
    </div>
</body>
</html>
